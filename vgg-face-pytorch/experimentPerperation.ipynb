{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","%cd \"/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\"\n","#!pip3 install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5G3RKSi6d7KN","executionInfo":{"status":"ok","timestamp":1659183665433,"user_tz":-120,"elapsed":27535,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"}},"outputId":"67e9aed3-e99e-4ce0-8760-e937d7156dba"},"id":"5G3RKSi6d7KN","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n"]}]},{"cell_type":"code","source":["!pip install mtcnn\n","!pip install torchfile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqm6LmVEnHeP","executionInfo":{"status":"ok","timestamp":1659183704505,"user_tz":-120,"elapsed":9862,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"}},"outputId":"5fd46db6-4d3d-426f-d5dc-f72212ff0794"},"id":"yqm6LmVEnHeP","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mtcnn\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.6.0.66)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)\n","Installing collected packages: mtcnn\n","Successfully installed mtcnn-0.1.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchfile\n","  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n","Building wheels for collected packages: torchfile\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=a300bd48fda88fe604c39eda505cc8775c351b7243a8e85e4c7e672f43fd42f5\n","  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n","Successfully built torchfile\n","Installing collected packages: torchfile\n","Successfully installed torchfile-0.1.0\n"]}]},{"cell_type":"markdown","source":["### Loading the data via the experiment dataloader\n","works fine now"],"metadata":{"id":"6sC3PqJhfFYK"},"id":"6sC3PqJhfFYK"},{"cell_type":"code","execution_count":4,"id":"35a2d187","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"35a2d187","executionInfo":{"status":"error","timestamp":1659183791795,"user_tz":-120,"elapsed":7764,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"}},"outputId":"abbfe4c2-9d30-49f6-82a9-3239528a5ae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","['aaron_staton', 'adam_copeland', 'amitabh_bachchan', 'andrew_rannells', 'ben_whishaw', 'chris_riggi', 'connie_nielsen', 'elaine_hendrix', 'eli_roth', 'jeannie_mai', 'jennifer_ferrin', 'john_mahoney', 'josh_lucas', 'katherine_jenkins', 'kathryn_mccormick', 'kelly_rowan', 'kiersten_warren', 'lana_wachowski', 'lauren_bowles', 'lennie_james', 'marshall_allman', 'michael_gambon', 'moran_atias', 'ralf_little', 'salli_richardson-whitfield', 'tommy_morrison', 'tracy_morgan', 'virginia_williams', 'wagner_moura', 'zac_efron']\n","Dataset size: 900 entries\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["%cd \"/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from models.utils import preprocess_data, data_process\n","import numpy as np\n","import argparse\n","import torchvision\n","import cv2\n","from torchvision import datasets, models, transforms\n","import sys\n","import numpy\n","from models.vgg_face import get_pretrained_model, get_prediction\n","import matplotlib.pyplot as plt # D.Griesser: import added\n","from image_utils import save_image, show_image  #\n","import torch.nn.functional as F\n","#uncomment to see some images \n","numpy.set_printoptions(threshold=sys.maxsize)\n","\n","\n","names = [line.rstrip('\\n') for line in open('data/names.txt')]\n","\n","batch_size = 10\n","\n","model = get_pretrained_model()\n","\n","model.eval()\n","\n","# torch.manual_seed(1234)\n","\n","dataloaders, _ = preprocess_data(batch_size)\n","\n","dataiter = iter(dataloaders)\n","data = dataiter.next()\n","\n","images, labels = data\n","\n","images = images[:,[2,1,0],:,:]\n","show_image(images)\n","\n","values, indices = get_prediction(images, model)\n","\n","# predictions = [(names[index], value) for index, value in zip(indices.tolist(), values.tolist())]\n","predictions = [names[index] for index in indices.tolist()]\n","ground_truth = [names[label] for label in labels.tolist()]   \n","\n","print(f\"Predictions: {predictions}\")\n","print(f\"Labels: {ground_truth}\")\n","print(f\"Num. correct predictions: {(labels == indices).sum().item()}\")"]},{"cell_type":"markdown","source":["### Loading the images by hand (no dataloader/dataset)\n","works fine --> images correctly classified"],"metadata":{"id":"T0bwX6BzEsVD"},"id":"T0bwX6BzEsVD"},{"cell_type":"code","execution_count":null,"id":"0219e0ae","metadata":{"id":"0219e0ae"},"outputs":[],"source":["# Model classifies images correctly\n","\n","import glob\n","import os\n","from google.colab.patches import cv2_imshow\n","\n","labels_dict = {\n","    \"aaron_staton\": 3,\n","    \"adam_copeland\": 17,\n","    \"amitabh_bachchan\": 101,\n","    \"andrew_rannells\": 119,\n","    \"ben_whishaw\": 202,\n","    \"chris_riggi\": 366,\n","    \"connie_nielsen\": 416,\n","    \"elaine_hendrix\": 632,\n","    \"eli_roth\": 636,\n","    \"jeannie_mai\": 1007,\n","    \"jennifer_ferrin\": 1040,\n","    \"john_mahoney\": 1164,\n","    \"josh_lucas\": 1224,\n","    \"katherine_jenkins\": 1296,\n","    \"kathryn_mccormick\": 1309,\n","    \"kelly_rowan\": 1363,\n","    \"kiersten_warren\": 1389,\n","    \"lana_wachowski\": 1427,\n","    \"lauren_bowles\": 1440,\n","    \"lennie_james\": 1464,\n","    \"marshall_allman\": 1630,\n","    \"michael_gambon\": 1737,\n","    \"moran_atias\": 1807,\n","    \"ralf_little\": 2019,\n","    \"salli_richardson-whitfield\": 2163,\n","    \"tommy_morrison\": 2485,\n","    \"tracy_morgan\": 2494,\n","    \"virginia_williams\": 2543,\n","    \"wagner_moura\": 2546,\n","    \"zac_efron\": 2603\n","}\n","\n","model = get_pretrained_model()\n","\n","model.eval()\n","\n","dir_list = glob.glob(\"/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch/data/experiment/images/*\")\n","\n","for dir in dir_list:\n","  class_name = dir.split(\"/\")[-1]\n","  files = os.listdir(dir + \"/\")\n","\n","  for i in range(30):\n","    path = dir + \"/\" + files[i] \n","    \n","    img = cv2.imread(path)\n","    img = cv2.resize(img, (224, 224))\n","\n","    # Forward test image through VGGFace\n","    image = torch.Tensor(img).permute(2, 0, 1).view(1, 3, 224, 224)\n","    image -= torch.Tensor(np.array([129.1863, 104.7624, 93.5940])).view(1, 3, 1, 1)\n","\n","    pred = F.softmax(model(image), dim=1)\n","    score, index = pred.max(-1)\n","    print(f\"Label: {class_name}; Prediction correct: {(index == labels_dict[class_name]).item()}\")\n","    \n","    # cv2_imshow(img)\n","    # print(f\"Prediction: {index}\")\n","    # print(f\"Label: {class_name}: {labels_dict[class_name]}\")\n","  \n"," "]},{"cell_type":"markdown","source":["### Loading the images of Wu et al. via the provided dataloader\n","images get classified correctly --> labels must be mapped"],"metadata":{"id":"1mcXZEkhE9pE"},"id":"1mcXZEkhE9pE"},{"cell_type":"code","source":["# test with only 10 classes --> works\n","\n","%cd \"/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from models.utils import preprocess_data, data_process\n","import numpy as np\n","import argparse\n","import torchvision\n","import cv2\n","from torchvision import datasets, models, transforms\n","import sys\n","import numpy\n","from models.vgg_face import get_pretrained_model, get_prediction\n","import matplotlib.pyplot as plt # D.Griesser: import added\n","from image_utils import save_image, show_image  #\n","import torch.nn.functional as F\n","#uncomment to see some images \n","numpy.set_printoptions(threshold=sys.maxsize)\n","\n","names = [line.rstrip('\\n') for line in open('data/names.txt')]\n","\n","labels_dict = {\n","    0 : 0,\n","    1 : 1,\n","    2 : 2,\n","    3 : 3,\n","    4 : 4,\n","    5 : 5,\n","    6 : 6,\n","    7 : 7,\n","    8 : 9,\n","    9 : 11\n","}\n","\n","\n","model = get_pretrained_model()\n","\n","model.eval()\n","batch_size = 100\n","\n","dataloaders, dataset_sizes = data_process(batch_size)\n","data = next(iter(dataloaders[\"test\"]))\n","\n","images, labels = data\n","      \n","images = images[:,[2,1,0],:,:] #rgb to bgr\n","\n","labels_mapped = torch.tensor([labels_dict[label] for label in labels.tolist()])\n","\n","l_names = [names[label] for label in labels.tolist()]\n","m_names = [names[label] for label in labels_mapped.tolist()]\n","\n","with torch.no_grad():\n","    model.eval()\n","\n","    # outputs = model(images)\n","    #_, predicted = torch.max(outputs.data, 1)\n","    preds = F.softmax(model(images), dim=1)\n","    _, predicted = preds.max(-1)\n","\n","print(predicted)\n","print(labels_mapped)\n","print(f\"Num. correct predictions: {(labels_mapped == predicted).sum().item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDQdzUNudEcb","executionInfo":{"status":"ok","timestamp":1659096667062,"user_tz":-120,"elapsed":106957,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"}},"outputId":"5b35811f-78fe-43e7-f7a3-63f64da75041"},"id":"PDQdzUNudEcb","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","['a_j__buckley', 'a_r__rahman', 'aamir_khan', 'aaron_staton', 'aaron_tveit', 'aaron_yoo', 'abbie_cornish', 'abel_ferrara', 'abigail_breslin', 'abigail_spencer']\n","{'test': 470}\n","tensor([  7,   5,   7,   5,   4,  11,   5,   3,   1,   1,   6,   0,   4,   9,\n","          0,   2,   4,   2,   6,   9,   9,   4,   2,   4,   7, 368,   2,   6,\n","          3,   7,   1,   1,   4,   5,   0,   7,   3,   4,  11,   1,   0,   0,\n","          2,   0,   1,   4,  11,   3,   4,   5,   2,   4,   9,   0,   1,   9,\n","          1,   2,  11,   4,   6,   6,   2,   1,   5,  11,   2,   6,   2,   6,\n","         11,   0,   3,   6,   5,  11,   3,   4,   2,   9,  11,   1,   7,   9,\n","         11,   1,   0,   2,   0,   6,   5,   1,   9,   4,   2,   4,   4,   6,\n","          6,   6])\n","tensor([ 7,  5,  7,  5,  4, 11,  5,  3,  1,  1,  6,  0,  4,  9,  0,  2,  4,  2,\n","         6,  9,  9,  4,  2,  4,  7,  4,  2,  6,  3,  7,  1,  1,  4,  5,  0,  7,\n","         3,  4, 11,  1,  0,  0,  2,  0,  1,  4, 11,  3,  4,  5,  2,  4,  9,  0,\n","         1,  9,  1,  2, 11,  4,  6,  6,  2,  1,  5, 11,  2,  6,  2,  6, 11,  0,\n","         3,  6,  5, 11,  3,  4,  2,  9, 11,  1,  7,  9, 11,  1,  0,  2,  0,  6,\n","         5,  1,  9,  4,  2,  4,  4,  6,  6,  6])\n","Num. correct predictions: 99\n"]}]},{"cell_type":"markdown","source":["### Loading the experiment images via the Wu et al. dataloader (modified)\n","images get classified correctly --> labels must be mapped"],"metadata":{"id":"DxCut1h2FTL-"},"id":"DxCut1h2FTL-"},{"cell_type":"code","source":["%cd \"/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from models.utils import preprocess_data, data_process\n","import numpy as np\n","import argparse\n","import torchvision\n","import cv2\n","from torchvision import datasets, models, transforms\n","import sys\n","import numpy\n","from models.vgg_face import get_pretrained_model, get_prediction\n","import matplotlib.pyplot as plt # D.Griesser: import added\n","from image_utils import save_image, show_image  #\n","import torch.nn.functional as F\n","#uncomment to see some images \n","numpy.set_printoptions(threshold=sys.maxsize)\n","\n","\n","\n","names = [line.rstrip('\\n') for line in open('data/names.txt')]\n","\n","labels_dict = {\n","    0 : 3,\n","    1 : 17,\n","    2 : 101,\n","    3 : 119,\n","    4 : 202,\n","    5 : 366,\n","    6 : 416,\n","    7 : 632,\n","    8 : 636,\n","    9 : 1007,\n","    10 : 1040,\n","    11 : 1164,\n","    12 : 1224,\n","    13 : 1296,\n","    14 : 1309,\n","    15 : 1363,\n","    16 : 1389,\n","    17 : 1427,\n","    18 : 1440,\n","    19 : 1464,\n","    20 : 1630,\n","    21 : 1737,\n","    22 : 1807,\n","    23 : 2019,\n","    24 : 2163,\n","    25 : 2485,\n","    26 : 2494,\n","    27 : 2543,\n","    28 : 2546,\n","    29 : 2603\n","}\n","\n","\n","model = get_pretrained_model()\n","\n","model.eval()\n","batch_size = 200\n","\n","dataloaders, dataset_sizes = data_process(batch_size)\n","\n","for i in range(5): \n","  data = next(iter(dataloaders[\"experiment/images\"]))\n","\n","  images, labels = data\n","        \n","  images = images[:,[2,1,0],:,:] #rgb to bgr\n","\n","  labels_mapped = torch.tensor([labels_dict[label] for label in labels.tolist()])\n","\n","  label_names = [names[label] for label in labels.tolist()]\n","  # print(label_names)\n","\n","  mapped_names = [names[label] for label in labels_mapped.tolist()]\n","  # print(mapped_names) \n","\n","  with torch.no_grad():\n","      model.eval()\n","\n","      # outputs = model(images)\n","      #_, predicted = torch.max(outputs.data, 1)\n","      preds = F.softmax(model(images), dim=1)\n","      _, predicted = preds.max(-1)\n","\n","  # print(predicted)\n","  # print(labels_mapped)\n","  print(f\"Num. correct predictions: {(labels_mapped == predicted).sum().item()}\")\n"],"metadata":{"id":"xptjTlPqOCIA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659098988081,"user_tz":-120,"elapsed":547329,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"}},"outputId":"1e2ba475-d176-469c-cfc4-72bcd430a757"},"id":"xptjTlPqOCIA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","['aaron_staton', 'adam_copeland', 'amitabh_bachchan', 'andrew_rannells', 'ben_whishaw', 'chris_riggi', 'connie_nielsen', 'elaine_hendrix', 'eli_roth', 'jeannie_mai', 'jennifer_ferrin', 'john_mahoney', 'josh_lucas', 'katherine_jenkins', 'kathryn_mccormick', 'kelly_rowan', 'kiersten_warren', 'lana_wachowski', 'lauren_bowles', 'lennie_james', 'marshall_allman', 'michael_gambon', 'moran_atias', 'ralf_little', 'salli_richardson-whitfield', 'tommy_morrison', 'tracy_morgan', 'virginia_williams', 'wagner_moura', 'zac_efron']\n","{'test': 470, 'experiment/images': 900}\n","Num. correct predictions: 200\n","Num. correct predictions: 200\n","Num. correct predictions: 200\n","Num. correct predictions: 200\n","Num. correct predictions: 199\n"]}]},{"cell_type":"markdown","source":["### Logging-Test"],"metadata":{"id":"LlXJscrvyYEp"},"id":"LlXJscrvyYEp"},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","\n","import logging \n","\n","logger = logging.getLogger(\"testlogger\")\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    filename=\"logs/test.log\",\n","    filemode=\"a\",\n","    format=\"%(asctime)s %(name)s %(levelname)s: %(message)s\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXZSZolKfO96","executionInfo":{"status":"ok","timestamp":1659179148815,"user_tz":-120,"elapsed":296,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"}},"outputId":"9788c652-bfe9-45c5-f2f1-b75a8f1328b8"},"id":"EXZSZolKfO96","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n"]}]},{"cell_type":"code","source":["for i in range(5):\n","  logger.info(f\"Test Nr. {i} im test-ordner\")"],"metadata":{"id":"f7QJuZm8nFPY"},"id":"f7QJuZm8nFPY","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"experimentPerperation.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}