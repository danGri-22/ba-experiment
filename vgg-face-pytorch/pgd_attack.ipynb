{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30089,"status":"ok","timestamp":1659347547388,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"},"user_tz":-120},"id":"mv3eZdd01BfR","outputId":"0e663c3c-a91c-4936-91b3-3359e3a034fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":25881,"status":"ok","timestamp":1659347663871,"user":{"displayName":"Daniel Griesser","userId":"07671905257156329868"},"user_tz":-120},"id":"9eCysjGm1KNU","outputId":"a15f909d-7301-4d43-bab1-2046a67c3025"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting adversarial_robustness_toolbox==1.11.0\n","  Downloading adversarial_robustness_toolbox-1.11.0-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 27.7 MB/s \n","\u001b[?25hCollecting art==5.7\n","  Downloading art-5.7-py2.py3-none-any.whl (592 kB)\n","\u001b[K     |████████████████████████████████| 592 kB 71.1 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n","Collecting mtcnn==0.1.1\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 54.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: opencv_python==4.6.0.66 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n","Requirement already satisfied: pandas==1.3.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.3.5)\n","Collecting Pillow==9.2.0\n","  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 55.5 MB/s \n","\u001b[?25hCollecting protobuf==3.20.*\n","  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.12.0+cu113 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.12.0+cu113)\n","Collecting torchfile==0.1.0\n","  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n","Requirement already satisfied: torchvision==0.13.0+cu113 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.13.0+cu113)\n","Collecting numba>=0.53.1\n","  Downloading numba-0.56.0-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 76.1 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (57.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (4.64.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (1.7.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 3)) (0.11.0)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn==0.1.1->-r requirements.txt (line 4)) (2.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.5->-r requirements.txt (line 7)) (2022.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.0+cu113->-r requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.13.0+cu113->-r requirements.txt (line 12)) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (4.12.0)\n","Collecting llvmlite<0.40,>=0.39.0dev0\n","  Downloading llvmlite-0.39.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n","\u001b[K     |████████████████████████████████| 34.6 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.53.1->adversarial_robustness_toolbox==1.11.0->-r requirements.txt (line 1)) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 12)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 12)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 12)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 12)) (2022.6.15)\n","Building wheels for collected packages: torchfile\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=eac00ff556652abe5145afebebf3cd183a48db4000176650dfec71099a486456\n","  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n","Successfully built torchfile\n","Installing collected packages: llvmlite, Pillow, numba, torchfile, protobuf, mtcnn, art, adversarial-robustness-toolbox\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.2+zzzcolab20220719082949 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed Pillow-9.2.0 adversarial-robustness-toolbox-1.11.0 art-5.7 llvmlite-0.39.0 mtcnn-0.1.1 numba-0.56.0 protobuf-3.20.1 torchfile-0.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","google"]}}},"metadata":{}}],"source":["%cd /content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"bZKSplJT276q"},"source":["### Dodging"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y99wqfQ_F5b8"},"outputs":[],"source":["%cd /content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import cv2\n","import sys\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torchvision import transforms\n","from models.utils import preprocess_data\n","from models.vgg_face import get_pretrained_model, get_prediction\n","from image_utils import save_image, show_image, compare_images\n","from art.attacks.evasion import ProjectedGradientDescent # will choose the correct version (e.g. pytorch) based on the classifier (e.g. PyTorchClassifier) used\n","from art.estimators.classification import PyTorchClassifier\n","import torch.optim as optim\n","import logging\n","from google.colab.patches import cv2_imshow\n","\n","np.set_printoptions(threshold=sys.maxsize)\n","\n","\n","logger = logging.getLogger(\"pgd_attack_dodging-logger\")\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    filename=\"logs/pgd_attack_dodging.log\",\n","    filemode=\"w\",\n","    format=\"%(asctime)s %(name)s %(levelname)s: %(message)s\"\n",")\n","\n","\n","names = [line.rstrip('\\n') for line in open('data/names.txt')]\n"," \n","BATCH_SIZE = 30\n","NUM_PASSES = 5\n","ITERA = [1, 2, 3, 5, 7, 10, 15, 20, 30]\n","ALPHA = 20\n","\n","model = get_pretrained_model()\n","\n","model.eval()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","\n","classifier = PyTorchClassifier(\n","    model=model,\n","    loss=criterion,\n","    optimizer=optimizer,\n","    nb_classes=2622,\n","    input_shape=(1, 3, 224, 224),\n","    device_type=\"gpu\"\n",")\n","\n","\n","glass = cv2.imread('data/glasses/silhouette.png')\n","glasses = glass.transpose(2, 0, 1).astype(\"float32\")\n","\n","\n","for i in range(len(ITERA)):\n","\n","  logger.info(f\"Num of attack iterations: {ITERA[i]}\")\n","  \n","  dataloaders, dataset_sizes = preprocess_data(BATCH_SIZE)\n","  dataiter = iter(dataloaders)\n","\n","  pgd_attack = ProjectedGradientDescent(estimator=classifier, eps=np.inf, eps_step=ALPHA, norm=np.inf, max_iter=ITERA[i])\n","\n","  for j in range(NUM_PASSES):\n","\n","    logger.info(f\"Run {j + 1}/{NUM_PASSES}\")\n","\n","    data = dataiter.next()\n","\n","    images, labels = data\n","\n","    images = images[:,[2,1,0],:,:].numpy()\n","    labels = labels.numpy()\n","\n","    x_adv = pgd_attack.generate(x=images, y=labels, batch_size=BATCH_SIZE, mask=glasses)\n","\n","    values, indices = get_prediction(torch.from_numpy(x_adv).to(device), model)\n","\n","    predictions = [(f\"id: {index}\", f\"name: {names[index]}\", f\"confidence: {value}\") for index, value in zip(indices.tolist(), values.tolist())]\n","    ground_truth = [(f\"id: {label}\", f\"name: {names[label]}\") for label in labels.tolist()]  \n","\n","    logger.info(f\"Predictions: {predictions}\\n\\n\"\\\n","                f\"Labels: {ground_truth}\\n\\n\" \\\n","                f\"Num. predictions: {labels.size}\\n\" \\\n","                f\"Num. correct predictions: {(indices == torch.from_numpy(labels).to(device)).sum().item()}\\n\\n\")\n","    \n","  save_image(f\"pgd_attack/dodging/iters{ITERA[i]}-{BATCH_SIZE}batch-\", torch.from_numpy(x_adv))\n"," "]},{"cell_type":"markdown","source":["### Impersonation"],"metadata":{"id":"RyjWcBpvgQDG"}},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/ColabNotebooks/BA/Experiment/vgg-face-pytorch\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import cv2\n","import sys\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torchvision import transforms\n","from models.utils import preprocess_data\n","from models.vgg_face import get_pretrained_model, get_prediction\n","from image_utils import save_image, show_image, compare_images\n","from art.attacks.evasion import ProjectedGradientDescent # will choose the correct version (e.g. pytorch) based on the classifier (e.g. PyTorchClassifier) used\n","from art.estimators.classification import PyTorchClassifier\n","import torch.optim as optim\n","import logging\n","from google.colab.patches import cv2_imshow\n","import random\n","\n","np.set_printoptions(threshold=sys.maxsize)\n","\n","\n","logger = logging.getLogger(\"pgd_attack_impersonation-logger\")\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    filename=\"logs/pgd_attack_impersonation.log\",\n","    filemode=\"w\",\n","    format=\"%(asctime)s %(name)s %(levelname)s: %(message)s\"\n",")\n","\n","\n","names = [line.rstrip('\\n') for line in open('data/names.txt')]\n"," \n","BATCH_SIZE = 30\n","NUM_PASSES = 5\n","ITERA = 30\n","ALPHA = 20\n","IMPERSONATION_ATTEMPTS = 3\n","\n","model = get_pretrained_model()\n","\n","model.eval()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","\n","classifier = PyTorchClassifier(\n","    model=model,\n","    loss=criterion,\n","    optimizer=optimizer,\n","    nb_classes=2622,\n","    input_shape=(1, 3, 224, 224),\n","    device_type=\"gpu\"\n",")\n","\n","\n","glass = cv2.imread('data/glasses/silhouette.png')\n","glasses = glass.transpose(2, 0, 1).astype(\"float32\")\n","\n","pgd_attack = ProjectedGradientDescent(estimator=classifier, eps=np.inf, eps_step=ALPHA, norm=np.inf, max_iter=ITERA, targeted=True)\n","\n","for i in range(IMPERSONATION_ATTEMPTS):\n","\n","  target = random.randint(0, 2621)\n","  target_tensor = torch.full((BATCH_SIZE,), target).numpy()\n","\n","  logger.info(f\"Attempt: {i + 1} - Target: (id: {target}, name: {names[target]})\")\n","  logger.info(f\"Num of attack iterations: {ITERA}\")\n","  \n","  dataloaders, dataset_sizes = preprocess_data(BATCH_SIZE)\n","  dataiter = iter(dataloaders)\n","\n","  for j in range(NUM_PASSES):\n","\n","    logger.info(f\"Run {j + 1}/{NUM_PASSES}\")\n","\n","    data = dataiter.next()\n","\n","    images, labels = data\n","\n","    images = images[:,[2,1,0],:,:].numpy()\n","    labels = labels.numpy()\n","\n","    x_adv = pgd_attack.generate(x=images, y=target_tensor, batch_size=BATCH_SIZE, mask=glasses)\n","\n","    values, indices = get_prediction(torch.from_numpy(x_adv).to(device), model)\n","\n","    predictions = [(f\"id: {index}\", f\"name: {names[index]}\", f\"confidence: {value}\") for index, value in zip(indices.tolist(), values.tolist())]\n","    ground_truth = [(f\"id: {label}\", f\"name: {names[label]}\") for label in labels.tolist()] \n","\n","    num_total_predictions = labels.size\n","    num_correct_predictions = (indices == torch.from_numpy(labels).to(device)).sum().item()\n","    num_successful_impersonation = (indices == torch.from_numpy(target_tensor).to(device)).sum().item()\n","    num_dodging = num_total_predictions - num_correct_predictions - num_successful_impersonation \n","    \n","    logger.info(f\"\\n\\nPredictions: {predictions}\\n\\n\"\\\n","                f\"Labels: {ground_truth}\\n\\n\" \\\n","                f\"Num. total predictions: {num_total_predictions}\\n\" \\\n","                f\"Num. correct predictions (indices == labels): {num_correct_predictions}\\n\" \\\n","                f\"Num. successful IMPERSONATION predictions (indices == targets): {num_successful_impersonation}\\n\" \\\n","                f\"Num. successful DODGING predictions (indices != labels && indices != targets): {num_dodging}\\n\\n\")\n","  \n","  save_image(f\"pgd_attack/impersonation/attempt{i}-iters{ITERA}-\", torch.from_numpy(x_adv))"],"metadata":{"id":"FCY-idlUgSbl"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"pgd_attack.ipynb","provenance":[],"authorship_tag":"ABX9TyNi0m0MORAUEUufeX4O6s/R"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}